# EIP 4844 的一些问答

## 1.什么是 Danksharding？

Danksharding 是为以太坊提出的新分片设计，与以前的设计相比，它引入了一些重要的简化。

自 2020 年以来所有最近的以太坊分片提案（包括 Danksharding 和 Danksharding 之前）与大多数非以太坊分片提案之间的主要区别是以太坊的以汇总为中心的路线图， 而不是为交易提供更多空间，以太坊分片为数据块提供更多空间，而以太坊协议本身并不试图解释这些数据。 验证 blob 只需要检查 blob 是否可用 - 它可以从网络下载。 这些 blob 中的数据空间预计将由支持高吞吐量事务的第 2 层汇总协议使用。

[![00](https://github.com/0xchaineye/chaineye-data-availability/blob/main/images/00.png)](https://github.com/savour-labs)


Danksharding 引入的主要创新（是合并的费用市场：在 Danksharding 中没有固定数量的分片，每个分片都有不同的块和不同的块提议者，只有 一个提议者选择进入该插槽的所有交易和所有数据。

为了避免这种设计对验证者提出高系统要求，我们引入了提议者/构建者分离（PBS）（称为区块构建者的一类特殊参与者竞标选择区块内容的权利 slot，提议者只需要选择出价最高的有效标头。 只有区块生成器需要处理整个区块（即使在那里，也可以使用第三方去中心化预言机协议来实现分布式区块生成器）； 所有其他验证者和用户都可以通过数据可用性采样非常有效地验证区块（请记住：区块的“大”部分只是数据）。


## 2.什么是 proto-danksharding（又名 EIP-4844）？

Proto-danksharding（又名 EIP-4844）是一项实施构成完整 Danksharding 规范的大部分逻辑和“脚手架”（例如交易格式、验证规则）的提案，但尚未实际实施任何分片。 在 proto-danksharding 实现中，所有验证者和用户仍然必须直接验证完整数据的可用性。

proto-danksharding 引入的主要特性是新的交易类型，我们称之为 blob-carrying 交易。 携带 blob 的事务与常规事务类似，只是它还携带称为 blob 的额外数据。 Blob 非常大 (~125 kB)，并且比类似数量的调用数据便宜得多。 但是，EVM 执行无法访问 blob 数据； EVM 只能查看对 blob 的承诺。

因为验证者和客户端仍然需要下载完整的 blob 内容，proto-danksharding 中的数据带宽目标是每个槽 1 MB，而不是完整的 16 MB。 然而，仍然有很大的可扩展性收益，因为该数据不会与现有以太坊交易的 gas 使用量竞争。


## 3.为什么向每个人都必须下载的块添加 1 MB 数据是可以的，而不只是让 calldata 便宜 10 倍？

这与平均负载和最坏情况负载之间的差异有关。 今天，我们已经遇到这样的情况，平均块大小约为 90 kB，但理论上最大可能的块大小（如果块中的所有 30M gas 都用于调用数据）约为 1.8 MB。 过去，以太坊网络处理的区块数量接近最大值。 然而，如果我们简单地将 calldata gas 成本降低 10 倍，那么虽然平均块大小会增加到仍然可以接受的水平，但最坏的情况会变成 18 MB，这对于以太坊网络来说太大了。

目前的 gas 定价方案无法将这两个因素分开：平均负载和最坏情况负载之间的比率取决于用户选择他们在 calldata 上花费多少 gas 与其他资源，这意味着 gas 价格必须是 基于最坏情况的可能性进行设置，导致平均负载不必要地低于系统可以处理的负载。 但是，如果我们改变 gas 定价以更明确地创建多维费用市场，我们可以避免平均情况/最坏情况负载不匹配，并在每个块中包含接近我们可以安全处理的最大数据量。 Proto-danksharding 和 EIP-4488 是两个完全这样做的提案。

|         |	Average case block size	 | Worst case block size|
|:-------:|:------------------------:|:--------------------|
|Status quo|        	85 kB	         |       1.8 MB        |
|EIP-4488	 | Unknown; 350 kB if 5x growth in calldata use	| 1.4 MB|
|Proto-danksharding	| 1 MB (tunable if desired)|	2 MB.   |


## 4.proto-danksharding (EIP-4844) 与 EIP-4488 相比如何？

EIP-4488 是解决相同平均情况/最坏情况负载不匹配问题的更早和更简单的尝试。 EIP-4488 使用两个简单的规则来做到这一点：

Calldata gas 成本从每字节 16 gas 降低到每字节 3 gas
每个块 1 MB 的限制加上每个事务额外的 300 字节（理论最大值：~1.4 MB）
硬限制是确保平均情况负载的较大增加不会导致最坏情况负载增加的最简单方法。 gas 成本的降低将大大增加 rollup 的使用，可能会将平均块大小增加到数百 KB，但硬限制将直接阻止单个块包含 10 MB 的最坏情况。 事实上，最坏情况下的块大小会比现在小（1.4 MB 对 1.8 MB）。

Proto-danksharding 相反创建了一个单独的交易类型，可以在大型固定大小的 blob 中保存更便宜的数据，每个块可以包含多少 blob。 这些 blob 不能从 EVM 访问（只有对 blob 的承诺可以），并且 blob 由共识层（信标链）而不是执行层存储。

EIP-4488 和 proto-danksharding 之间的主要实际区别在于，EIP-4488 试图将今天所需的更改降至最低，而 proto-danksharding 今天进行了大量更改，因此将来升级到完整分片所需的更改很少 . 尽管实现完全分片（使用数据可用性采样等）是一项复杂的任务，并且在 proto-danksharding 之后仍然是一项复杂的任务，但这种复杂性包含在共识层中。 一旦 proto-danksharding 推出，执行层客户端团队、rollup 开发人员和用户无需做进一步的工作即可完成向完全分片的过渡。 Proto-danksharding 还将 blob 数据与 calldata 分开，使客户端更容易在较短的时间内存储 blob 数据。

请注意，两者之间的选择不是非此即彼：我们可以很快实施 EIP-4488，然后在半年后使用 proto-danksharding 跟进。

## 5.proto-danksharding 实现了完整的 danksharding 的哪些部分，还有哪些有待实现？

引用 EIP-4844：

该 EIP 中已经完成的工作包括：

- 一种新的交易类型，其格式完全相同，需要存在于“全分片”中
- 全分片所需的所有执行层逻辑
- 全分片所需的所有执行/共识交叉验证逻辑
- BeaconBlock 验证和数据可用性采样 blob 之间的层分离
- 完整分片所需的大部分 BeaconBlock 逻辑
- blob 的自我调整的独立 gasprice。

要实现完全分片，还有待完成的工作包括：

- 共识层中 blob_kzgs 的低度扩展以允许 2D 采样
- 数据可用性采样的实际实现
- PBS（提议者/构建者分离），以避免要求单个验证者在一个时隙中处理 32 MB 的数据
- 每个验证器的保管证明或类似的协议内要求，以验证每个块中分片数据的特定部分

请注意，所有剩余的工作都是共识层更改，不需要执行客户端团队、用户或汇总开发人员的任何额外工作。


## 6.从所有这些非常大的块中爆炸的磁盘空间需求怎么样？

EIP-4488 和 proto-danksharding 都会导致每个插槽（12 秒）的长期最大使用量约为 1 MB。 这相当于每年约 2.5 TB，远高于以太坊今天所需的增长率。

在 EIP-4488 的情况下，解决这个问题需要历史过期（EIP-4444），客户端不再需要存储超过某个持续时间的历史（已提议从 1 个月到 1 年的持续时间）。

在 proto-danksharding 的情况下，共识层可以实现单独的逻辑来在一段时间后（例如 30 天）自动删除 blob 数据，无论是否实现了 EIP-4444。 但是，无论采用何种短期数据扩展解决方案，都强烈建议尽快实施 EIP-4444。

这两种策略都将共识客户端的额外磁盘负载限制在最多几百 GB。 从长远来看，采用一些历史过期机制本质上是强制性的：全分片每年会增加大约 40 TB 的历史 blob 数据，因此用户实际上只能存储其中的一小部分一段时间。 因此，值得尽快设定对此的期望。

## 7.如果数据在 30 天后被删除，用户将如何访问旧的 blob？

以太坊共识协议的目的并不是保证所有历史数据永远保存。 相反，目的是提供一个高度安全的实时公告板，并为其他去中心化协议留出空间来进行更长期的存储。 布告栏是为了确保布告栏上发布的数据有足够长的可用时间，以便任何需要该数据或任何备份数据的长期协议的用户都有足够的时间来获取数据并导入它 进入他们的其他应用程序或协议。

一般来说，长期的历史存储很容易。 虽然每年 2.5 TB 的容量对于常规节点来说太多了，但对于专用用户来说却很容易管理：您可以以每 TB 约 20 美元的价格购买非常大的硬盘驱动器，这在业余爱好者的能力范围内。 与具有 N/2-of-N 信任模型的共识不同，历史存储具有 1-of-N 信任模型：您只需要数据存储者之一是诚实的。 因此，每条历史数据只需要存储数百次，而不是实时共识验证的数千个节点的完整集合。

存储完整历史记录并使其易于访问的一些实用方法包括：

- 特定于应用程序的协议（例如汇总）可能要求其节点存储与其应用程序相关的历史部分。 历史数据丢失不会对协议造成风险，只会对单个应用程序造成风险，因此应用程序承担存储与自身相关的数据的负担是有意义的。
- 在 BitTorrent 中存储历史数据，例如。 每天自动生成和分发一个 7 GB 的文件，其中包含来自块的 blob 数据。
- 以太坊门户网络（目前正在开发中）可以很容易地扩展到存储历史记录。
- 区块浏览器、API 提供者和其他数据服务可能会存储完整的历史记录。
- 个人爱好者和进行数据分析的学者可能会存储完整的历史记录。 在后一种情况下，在本地存储历史为他们提供了重要的价值，因为它使得直接对其进行计算变得更加容易。
- TheGraph 等第三方索引协议可能会存储完整的历史记录。

在更高级别的历史存储（例如每年 500 TB）下，某些数据被遗忘的风险变得更高（此外，数据可用性验证系统变得更加紧张）。 这可能是分片区块链可扩展性的真正限制。 然而，目前所有提出的参数都远未达到这一点。


## 8.blob 数据的格式是什么？它是如何提交的？

一个 blob 是一个包含 4096 个字段元素的向量，数字在以下范围内：

0 <= x < 52435875175126190479447740508185965837690552500527637822603658699938581184513

blob 在数学上被视为表示具有上述模数的有限域上 < 4096 的多项式，其中域元素位于位置 i 在 blob 中是多项式的评估 ω^i, ω 是满足的常数 ω^4096 = 1

对 blob 的承诺是 KZG 对多项式承诺的散列。 然而，从实现的角度来看，关注多项式的数学细节并不重要。 相反，只会有一个椭圆曲线点的向量（基于拉格朗日的可信设置），而 KZG 对 blob 的承诺将只是一个线性组合。 引用 EIP-4844 中的代码：

```
def blob_to_kzg(blob: Vector[BLSFieldElement, 4096]) -> KZGCommitment:
    computed_kzg = bls.Z1
    for value, point_kzg in zip(tx.blob, KZG_SETUP_LAGRANGE):
        assert value < BLS_MODULUS
        computed_kzg = bls.add(
            computed_kzg,
            bls.multiply(point_kzg, value)
        )
    return computed_kzg
```

BLS_MODULUS 是上述模数，KZG_SETUP_LAGRANGE 是拉格朗日基可信设置的椭圆曲线点向量。 对于实施者来说，现在将其简单地视为黑盒专用哈希函数是合理的。


## 9.为什么直接使用KZG的hash而不是KZG？

EIP-4844 没有使用 KZG 直接表示 blob，而是使用版本哈希：单个 0x01 字节（表示版本）后跟 KZG 的 SHA256 哈希的最后 31 个字节。

这样做是为了 EVM 兼容性和未来兼容性：KZG 承诺是 48 字节，而 EVM 更自然地使用 32 字节值，如果我们从 KZG 切换到其他东西（例如，出于抗量子原因），承诺 可以继续是32字节。

## 10.proto-danksharding 中引入的两个预编译是什么？

Proto-danksharding 引入了两种预编译：blob 验证预编译和点评估预编译。

blob 验证预编译是不言自明的：它将版本化哈希和 blob 作为输入，并验证提供的版本化哈希实际上是 blob 的有效版本化哈希。 此预编译旨在供 optimistic rollups 使用。 引用 EIP-4844：

> Optimistic rollups 只需要在提交欺诈证明时实际提供基础数据。 欺诈证明提交功能将要求将欺诈性 blob 的全部内容作为调用数据的一部分提交。 它将使用 blob 验证功能根据之前提交的版本化哈希验证数据，然后像今天一样对该数据执行欺诈证明验证。

点评估预编译将版本化哈希、x 坐标、y 坐标和证明（blob 的 KZG 承诺和 KZG 评估证明）作为输入。 它验证证明以检查 P(x) = y，其中 P 是由具有给定版本化哈希的 blob 表示的多项式。 此预编译旨在供 ZK 汇总使用。 引用 EIP-4844：

> ZK 汇总将为其交易或状态增量数据提供两个承诺：blob 中的 kzg 和使用 ZK 汇总内部使用的任何证明系统的一些承诺。 他们将使用等价协议的承诺证明，使用点评估预编译来证明 kzg（协议确保指向可用数据）和 ZK rollup 自己的承诺引用相同的数据。

请注意，大多数主要的 optimistic rollup 设计都使用多轮欺诈证明方案，其中最后一轮只需要少量数据。 因此，可以想象，optimistic rollups 也可以使用点评估预编译而不是 blob 验证预编译，而且这样做会更便宜。

 ## 11. ZK rollups 究竟如何有效地与 KZG 承诺配合使用？
 
 在 ZK rollup 中检查 blob 的“naive”方法是将 blob 数据作为私有输入传递给 KZG，并在 SNARK 中进行椭圆曲线线性组合（或配对）来验证它。 这是错误的，而且效率低下。 相反，在 ZK rollup 基于 BLS12-381 的情况下，有一种更简单的方法，对于任意 ZK-SNARK，有一种更简单的方法。

#### 简单方法（需要汇总才能使用 BLS12-381 模数）

假设 K 是 KZG 的承诺，并且 B 是它承诺的 blob。 所有 ZK-SNARK 协议都有一些方法可以将大量数据导入证明，并包含对该数据的某种承诺。 例如，在 PLONK 中这是
Qc 承诺。 我们所要做的就是证明 K 和 Qc 致力于相同的数据。 这可以通过等价证明来完成，这非常简单。 从帖子中复制：

> 假设您有多个多项式承诺 Ci …… Ck， 在下面 k 不同的承诺方案（例如 Kate、FRI、基于防弹的东西、DARK……），并且您想证明它们都承诺相同的多项式 P. 我们可以很容易地证明这一点： 让 z = HASH(Ci …… Ck)，我们在这里解释 z 作为评估点 P 可以评估。发布公开的 O1...Ok， 在哪里 Oi 是一个证明 Ci(Z) = a, 在 i 的承诺计划下。 验证 a 在所有情况下都是相同的数字。

ZK rollup 交易只需要有一个常规的 SNARK，以及这种等价性证明，以证明其公共数据等于版本化哈希。 请注意，他们不应该直接执行 KZG 检查； 相反，他们应该只使用点评估预编译来验证开口。 这确保了面向未来：如果以后 KZG 被其他东西取代，ZK rollup 将能够继续工作而不会出现进一步的问题。


#### 中等方法：适用于任何 ZK-SNARK

如果目标 ZK-SNARK 使用其他模数，甚至根本不是基于多项式的（例如，它使用 R1CS），则有一种稍微复杂的方法可以证明等价性。 证明工作如下：


1. 让 P(X) 是由 blob 编码的多项式。 做出承诺 Qz 在对值进行编码的 ZK-SNARK 方案中 V1...Vn， 在哪里 Vi==P(ωi).
2. 选择 X 通过散列承诺 P 和 Q.
3. 证明 P(X) 用点评估预编译。
4. 使用重心方程在 P(x) = (x^N - 1/N) * ∑i Vi * w^i / x-w^i,ZKP 内部执行相同的评估。 验证答案是否与中证明的值相同

(4) 需要使用不匹配字段算法来完成，但是 PLOOKUP 风格的技术可以用比算术友好的哈希函数更少的约束来完成。 注意 x^N - 1/N 和 w^i 可以预先计算并保存，使计算更简单。
 

## 11. KZG 可信设置是什么样的？

- https://vitalik.ca/general/2022/03/14/trustedsetup.html 有关 powers-of-tau 可信设置如何工作的一般描述
- https://github.com/ethereum/research/blob/master/trusted_setup/trusted_setup.py 用于所有重要的可信设置相关计算的示例实现

特别是在我们的案例中，目前的计划是同时进行四个大小不同的仪式（具有不同的秘密）(n1=4096,n2=16), (n1=8192,n2=16), (n1=16384,n2=16) 和 (n1=32768,n2=16). 从理论上讲，只需要第一个，但运行更多的更大尺寸通过允许我们增加 blob 大小来提高未来的适应性。 我们不能只是有一个更大的设置，因为我们希望能够对可以有效提交的多项式的次数有一个硬性限制，并且这个限制等于 blob 大小。

执行此操作的可能实用方法是从 Filecoin 设置开始，然后运行一个仪式来扩展它。 多个实现，包括浏览器实现，将允许许多人参与。

## 12.我们不能在没有可信设置的情况下使用其他承诺方案吗？

不幸的是，使用 KZG 以外的任何东西（例如 IPA 或 SHA256）会使分片路线图变得更加困难。 这是出于以下几个原因：

- 非算术承诺（例如哈希函数）与数据可用性抽样不兼容，因此如果我们使用这样的方案，则在我们转向全分片时无论如何都必须更改为 KZG。
- IPA 可能与数据可用性抽样兼容，但它会导致具有更弱属性的更复杂的方案（例如，自我修复和分布式块构建变得更难）
- 哈希和 IPA 都不兼容点评估预编译的廉价实现。 因此，基于哈希或 IPA 的实现将无法有效地使 ZK rollups 受益或支持多轮 optimistic rollups 中的廉价欺诈证明。
- 保持数据可用性采样和点评估但引入另一个承诺的一种方法是为每个 blob 存储多个承诺（例如 KZG 和 SHA256）。 但这有一个问题，要么（i）我们需要添加一个复杂的 ZKP 等价证明，要么（ii）所有共识节点都需要验证第二个承诺，这将要求他们下载所有 blob 的完整数据（十个） 每个插槽的兆字节数）。

因此，不幸的是，使用 KZG 以外的任何东西所造成的功能损失和复杂性增加远大于 KZG 本身的风险。 此外，任何与 KZG 相关的风险都包含在内：KZG 故障只会影响 rollups 和其他依赖于 blob 数据的应用程序，而不会影响系统的其余部分。

## 13.KZG有多“复杂”和“新”？

KZG 承诺于 2010 年在一篇论文中引入，自 2019 年以来已在 PLONK 式 ZK-SNARK 协议中广泛使用。 然而，KZG 承诺的基础数学是在椭圆曲线运算和配对的基础数学之上的相对简单的算术。

使用的具体曲线是 BLS12-381，它是由 Barreto-Lynn-Scott 家族于 2002 年发明的。验证 KZG 承诺所必需的椭圆曲线对是非常复杂的数学，但它们是 1940 年代发明的并应用于加密货币 自 1990 年代以来。 到 2001 年，提出了许多使用配对的密码算法。

从实现复杂性的角度来看，KZG 并不比 IPA 更难实现：计算承诺的函数（见上文）与 IPA 情况完全相同，只是具有一组不同的椭圆曲线点常数。 点验证预编译更复杂，因为它涉及配对评估，但数学与 EIP-2537（BLS12-381 预编译）实现中已经完成的部分相同，并且与 bn128 配对预编译非常相似（ 另请参阅：优化的 python 实现）。 因此，实施 KZG 验证不需要复杂的“新工作”。

## 14. proto-danksharding 实现的不同软件部分是什么？

有四个主要组成部分：

#### 执行层共识变化（详见EIP）：

- 包含 blob 的新事务类型
- 在当前交易中输出第 i 个 blob 版本哈希的操作码
- Blob 验证预编译
- 点评估预编译

#### 共识层共识发生变化（请参阅 repo 中的此文件夹）：
- BeaconBlockBody 中的 blob KZG 列表
- “sidecar”机制，其中完整的 blob 内容与来自 BeaconBlock 的单独对象一起传递
- 执行层中的 blob 版本化哈希与共识层中的 blob KZG 之间的交叉检查

#### 内存池
- BlobTransactionNetworkWrapper（参见 EIP 的网络部分）
- 更强大的反 DoS 保护以补偿较大的 blob 大小

####  区块构建逻辑
接受来自内存池的交易包装器，将交易放入 ExecutionPayload，将 KZG 放入信标块，将主体放入边车中
应对二次元收费市场

请注意，对于最小的实现，我们根本不需要内存池（我们可以依赖第二层交易捆绑市场），我们只需要一个客户端来实现区块构建逻辑。 仅对执行层和共识层共识变更进行广泛的共识测试，相对轻量级。 介于这种最小实现和“完整”部署之间的任何东西，其中所有客户端都支持块生产并且内存池是可能的。

## 15.proto-danksharding 多维费用市场是什么样的？

Proto-danksharding 引入了一个多维度的 EIP-1559 费用市场，其中有两种资源，gas 和 blob，具有独立的浮动 gas 价格和独立的限制。

也就是说，有两个变量和四个常量：

|       |	Target per block	| Max per block	| Basefee   |
|:-----:|:----------------------:|:--------------:|:--------:|
| Gas	|       15 million	     |  30 million	  | Variable |
| Blob  |        8	             |  16	          | Variable |


blob 费用以 gas 计费，但它是可变数量的 gas，它会进行调整，以便从长远来看每个区块的平均 blob 数量实际上等于目标。

二维性质意味着区块构建者将面临一个更难的问题：他们不能简单地接受具有最高优先级费用的交易，直到他们用完交易或达到区块 gas 限制，他们将不得不同时避免达到两个不同的 限制。

这是一个例子。 假设 gas limit 是 70，blob limit 是 40。mempool 有很多交易，足以填满区块，有两种类型（tx gas 包括 per-blob gas）：

- Priority fee 5 per gas, 4 blobs, 4 gas
- Priority Fee 3 per gas, 1 blob, 2 total gas

遵循天真的“降低优先费用”算法的矿工将用第一种类型的 10 笔交易（40 gas）填充整个区块，并获得 5 * 40 = 200 的收入。因为这 10 笔交易填满了 blob 完全限制，他们将无法包含更多交易。 但最佳策略是取 3 个第一种交易和 28 个第二种交易。 这为您提供了一个包含 40 个 blob 和 68 个气体的区块，以及 5 * 12 + 3 * 56 = 228 的收入。

[![01](https://github.com/0xchaineye/chaineye-data-availability/blob/main/images/01.png)](https://github.com/savour-labs)

执行客户现在是否必须实施复杂的多维背包问题算法来优化他们的区块生产？ 不，有几个原因：


- EIP-1559 确保大多数区块不会达到任何一个限制，因此实际上只有少数区块面临多维优化问题。 在 mempool 没有足够（足够的费用支付）交易来达到任一限制的通常情况下，任何矿工都可以通过包括他们看到的每笔交易来获得最佳收入。
- 相当简单的启发式方法在实践中可以接近最优。 请参阅 Ansgar 的 EIP-4488 分析，了解类似情况下的一些相关数据。
- 多维定价甚至不是专业化带来的最大收入来源——MEV 才是。 通过专门算法从链上 DEX 仲裁、清算、先行 NFT 销售等中提取的专门 MEV 收入占总可退还额外费用的很大一部分”（即优先费用）：专门 MEV 收入似乎平均约为每个区块 0.025 ETH ，并且优先权总费用通常约为每个区块 0.1 ETH。
- 提议者/建造者分离是围绕高度专业化的区块生产而设计的。 PBS 将区块构建过程转变为拍卖，专业参与者可以在拍卖中竞标创建区块的特权。 常规验证者只需要接受最高出价。 以防止 MEV 驱动的规模经济蔓延到验证者中心化，但它处理了所有可能使最佳区块构建变得更加困难的问题。

由于这些原因，更复杂的费用市场动态不会大大增加中心化或风险； 事实上，更广泛应用的原则实际上可以降低拒绝服务风险！


## 16.指数型 EIP-1559 blob 费用调整机制如何运作？

[eip4844里面的解释](https://www.eip4844.com/)

## 17.fake_exponential 是如何工作的？
为方便起见，这里是 fake_exponential 的代码：
```
def fake_exponential(numerator: int, denominator: int) -> int:
    cofactor = 2 ** (numerator // denominator)
    fractional = numerator % denominator
    return cofactor + (
        fractional * cofactor * 2 +
        (fractional ** 2 * cofactor) // denominator
    ) // (denominator * 3)
```

这里是用数学重新表达的核心机制，去掉了四舍五入：

[![03](https://github.com/0xchaineye/chaineye-data-availability/blob/main/images/03.png)](https://github.com/savour-labs)

[![04](https://github.com/0xchaineye/chaineye-data-availability/blob/main/images/04.png)](https://github.com/savour-labs)

[![05](https://github.com/0xchaineye/chaineye-data-availability/blob/main/images/05.png)](https://github.com/savour-labs)


## 18.proto-danksharding 中有哪些问题仍在争论中？

注意：此部分很容易变得过时。 不要相信它会给出任何特定问题的最新想法。

- 所有主要的 optimistic rollups 都使用多轮证明，因此它们可以使用（便宜得多的）点评估预编译而不是 blob 验证预编译。 任何真正需要 blob 验证的人都可以自己实现它：将 blob 作为输入
D 和版本哈希 h， 选择 X= Hash(D, h), 使用重心评估来计算 y = D(x) 并使用点评估预编译来验证 h(x) = y. 因此，我们真的需要 blob 验证预编译，还是我们可以删除它并只使用点评估？
- 链条如何处理持久的长期 1 MB+ 块？ 如果风险太大，是否应该在开始时减少目标 blob 数量？
- blob 应该以 gas 还是以 ETH（被销毁）定价？ 是否应该对费用市场进行其他调整？
- 新交易类型应该被视为 blob 还是 SSZ 对象，在后一种情况下将 ExecutionPayload 更改为联合类型？ （这是“现在更多工作”与“以后更多工作”的权衡）
- 可信设置实施的确切细节（技术上超出了 EIP 本身的范围，因为对于实施者来说，设置“只是一个常量”，但仍然需要完成）。

